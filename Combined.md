# This file was generated by the Combine Files to Markdown script

## File: file_handler.py
```py
# ./file_handler.py
# This module handles file operations, including reading JSON files.

import json
import logging

class FileHandler:
    def __init__(self):
        logging.basicConfig(level=logging.INFO)

    def read_json_file(self, file_path):
        """
        Reads and returns the content of a JSON file.
        Args:
        - file_path (str): The path to the JSON file.

        Returns:
        - dict: The content of the JSON file if successful, None otherwise.
        """
        try:
            with open(file_path, 'r') as file:
                return json.load(file)
        except FileNotFoundError:
            logging.error(f"File not found: {file_path}")
            return None
        except json.JSONDecodeError as e:
            logging.error(f"Error decoding JSON from {file_path}: {e}")
            return None

    def write_json_file(self, file_path, data):
        """
        Writes the given data to a JSON file.

        Args:
            file_path (str): The path to the JSON file.
            data (dict): The data to write to the file.
        """
        try:
            with open(file_path, 'w') as file:
                json.dump(data, file, indent=4)
            logging.info(f"Data successfully written to {file_path}")
        except Exception as e:
            logging.error(f"Failed to write data to {file_path}: {e}")
            raise

```

## File: markdown_converter.py
```py
# ./markdown_converter.py
"""
MarkdownConverter Module
------------------------
Responsible for converting JSON data to Markdown format. This module is utilized in 
transforming task data into a readable Markdown format, enhancing the user's understanding 
and interaction with the data.

Classes:
- MarkdownConverter: Converts JSON data to a well-structured Markdown format.

Dependencies:
- logging: To log error messages and informational messages.
"""

import logging

class MarkdownConverter:
    def __init__(self):
        """
        Initializes the MarkdownConverter with basic logging configuration.
        """
        logging.basicConfig(level=logging.INFO)

    def convert_to_markdown(self, data):
        print(data)
        """
        Converts JSON data to Markdown format.

        Args:
            data (dict): The JSON data to be converted.

        Returns:
            str: The converted Markdown string, or an error message in case of failure.
        """
        try:
            md_content = data.get("overview", "") + "\n\n"

            # Check if the data contains a single subtask or multiple tasks
            if 'tasks' in data:
                for task_key, task_info in data["tasks"].items():
                    if 'description' in task_info:
                        # Main task with description and subtasks
                        md_content += f"## [{'x' if task_info['status'] else ' '}] {task_key}. {task_info['description']}\n"
                        for subtask_key, subtask_info in task_info.items():
                            if isinstance(subtask_info, dict) and 'task' in subtask_info:
                                md_content += f"- [{'x' if subtask_info['status'] else ' '}] {subtask_key}. {subtask_info['task']}\n"
                        md_content += "\n"
                    else:
                        # Individual subtask without a main task
                        md_content += f"- [{'x' if task_info['status'] else ' '}] {task_key}. {task_info['task']}\n"
            else:
                # Fallback for unexpected data format
                md_content += "Error: Unrecognized data format for Markdown conversion.\n"

            return md_content
        except Exception as e:
            logging.error(f"Error converting JSON to Markdown: {e}")
            return "Error in Markdown conversion"

# Example usage:
# converter = MarkdownConverter()
# markdown_text = converter.convert_to_markdown(json_data)

```

## File: api_authenticator.py
```py
# ./api_authenticator.py
import json
import functools
from flask import request, jsonify
import logging

class APIAuthenticator:
    def __init__(self):
        """
        Initializes the APIAuthenticator. API keys will be loaded dynamically per request.
        """
        self.api_keys = {}

    def load_api_keys(self, api_keys_file):
        """
        Load API keys from a specified JSON file.

        Args:
            api_keys_file (str): The path to the JSON file containing API keys.
        """
        try:
            with open(api_keys_file, 'r') as file:
                self.api_keys = json.load(file)
        except FileNotFoundError:
            logging.error(f"API keys file not found: {api_keys_file}")
            self.api_keys = {}

    def require_api_key(self, view_function):
        """
        Decorator function to secure routes with API key authentication.

        Args:
            view_function (function): The Flask view function to decorate.

        Returns:
            function: The decorated view function with API key authentication.
        """
        @functools.wraps(view_function)
        def decorated_function(*args, **kwargs):
            # Extract project name from URL path parameter
            project_name = kwargs.get('project_name')
            if project_name:
                api_keys_file = f"./users/{project_name}.json"
                self.load_api_keys(api_keys_file)
            else:
                logging.error("Project name not provided in the URL.")
                return jsonify({"error": "Project name required"}), 400

            api_key = request.headers.get('X-API-Key')
            if api_key and api_key in self.api_keys:
                return view_function(*args, **kwargs)
            else:
                logging.warning("Unauthorized access attempt.")
                return jsonify({"error": "Unauthorized"}), 401

        return decorated_function

# Create an instance
api_auth_instance = APIAuthenticator()

```

## File: task_routes.py
```py
# ./task_routes.py
"""
Task Routes Module
------------------
Defines the Flask routes for task-related operations. This module interfaces with the FileHandler, 
TaskExtractor, and MarkdownConverter classes to manage tasks. It includes functionality for 
retrieving, updating, and 'deleting' tasks, with each operation secured through API key authentication 
and detailed logging for monitoring and debugging.

Functions:
- get_task: Retrieves task data from a specified file.
- update_task: Updates the details of a specific task.
- delete_task: Marks a task as deleted in the task file.

Dependencies:
- FileHandler: Module for handling file operations.
- TaskExtractor: Module for extracting specific tasks or subtasks.
- MarkdownConverter: Module for converting tasks to Markdown format.
- require_api_key: Decorator from api_authenticator for API key validation.
"""

from flask import Blueprint, request, jsonify
from file_handler import FileHandler
from task_extractor import TaskExtractor
from markdown_converter import MarkdownConverter
from api_authenticator import api_auth_instance
import logging
import shutil
from datetime import datetime
import os

# Initialize Blueprint for task routes
task_blueprint = Blueprint('task_routes', __name__)
file_handler = FileHandler()
task_extractor = TaskExtractor()
markdown_converter = MarkdownConverter()

@task_blueprint.route('/<project_name>', methods=['GET'])
@task_blueprint.route('/<project_name>/<task_number>', methods=['GET'])
# @api_auth_instance.require_api_key
def get_task(project_name, task_number=None):
    """
    Retrieves and returns the specified task or subtask data from a JSON file.

    Args:
        project_name (str): The name of the JSON file containing tasks.
        task_number (str, optional): The specific task number to retrieve, can include subtasks like '1.1'.

    Returns:
        JSON or Markdown formatted string of the task data, or an error message.
    """
    format_type = request.args.get('format', 'json')
    file_path = f'tasks/{project_name}.json'

    logging.info(f"Retrieving tasks from {file_path}")
    tasks_data = file_handler.read_json_file(file_path)
    
    if tasks_data is None:
        logging.error("Task file not found")
        return jsonify({'error': 'File not found'}), 404

    if task_number:
        tasks_data = task_extractor.extract_task_data(tasks_data, task_number)
        if tasks_data is None:
            logging.error("Specific task or subtask not found")
            return jsonify({'error': 'Task or subtask not found'}), 404

    if format_type == 'md':
        markdown_content = markdown_converter.convert_to_markdown(tasks_data)
        return markdown_content, 200, {'Content-Type': 'text/markdown'}

    return jsonify(tasks_data), 200

@task_blueprint.route('/<project_name>/<task_number>', methods=['PUT'])
def update_task(project_name, task_number):
    data = request.json
    file_path = f'tasks/{project_name}.json'

    # Create a backup before updating
    backup_dir = './tasks/backups/'
    os.makedirs(backup_dir, exist_ok=True)  # Create backups directory if it doesn't exist
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    backup_file_path = f'{backup_dir}datetime_{project_name}_{timestamp}.json'
    shutil.copy(file_path, backup_file_path)
    logging.info(f"Backup created at {backup_file_path}")


    tasks_data = file_handler.read_json_file(file_path)
    if tasks_data is None:
        return jsonify({'error': 'File not found'}), 404

    try:
        if '.' in task_number:
            # Handle subtask
            main_task, subtask_id = task_number.split('.', 1)
            task_data = tasks_data['tasks'][main_task][task_number]
        else:
            # Handle main task
            task_data = tasks_data['tasks'][task_number]

        # Update status and/or description
        if 'status' in data:
            task_data['status'] = data['status']
        if 'description' in data and '.' not in task_number:
            task_data['description'] = data['description']

        # Write the updated data back to the file
        file_handler.write_json_file(file_path, tasks_data)
        return jsonify({"message": "Task updated successfully"}), 200

    except KeyError as e:
        logging.error(f"Task or subtask not found: {e}")
        return jsonify({'error': 'Task or subtask not found'}), 404
    except Exception as e:
        logging.exception(f"An error occurred while updating the task: {e}")
        return jsonify({'error': 'An error occurred while updating the task'}), 500
```

## File: notes_routes.py
```py
# ./notes_routes.py
"""
Notes Routes Module
-------------------
Defines the Flask routes for notes-related operations. It handles the addition,
updating, and deletion of notes, interfacing with the NotesManager class. Each operation is
secured with API key authentication and includes detailed logging for monitoring and debugging.

Functions:
- add_note: Adds a new note to the specified notes file.
- update_note: Updates an existing note in the specified notes file.
- delete_note: Deletes a note from the specified notes file.
- get_notes: Retrieves notes from the specified file, optionally in Markdown format.

Dependencies:
- NotesManager: Class from notes_manager module for managing note operations.
- MarkdownConverter: Class for converting JSON data to Markdown format.
- require_api_key: Decorator from api_authenticator for API key validation.
"""

from flask import Blueprint, request, jsonify
from notes_manager import NotesManager
from markdown_converter import MarkdownConverter
from api_authenticator import api_auth_instance
import logging

notes_blueprint = Blueprint('notes_routes', __name__)

@notes_blueprint.route('/<project_name>', methods=['GET'])
@api_auth_instance.require_api_key
def get_notes(project_name):
    """
    Retrieves notes from the specified file, optionally formatted in Markdown.

    Args:
        project_name (str): The project_name of the notes file.

    Returns:
        JSON or Markdown formatted string of the notes, or an error message.

    This endpoint checks for a query parameter 'format'. If 'format=md' is specified,
    the notes are returned in Markdown format. Otherwise, the notes are returned in JSON format.
    """
    format_type = request.args.get('format', 'json')  # Get the format type from query parameters
    notes_manager = NotesManager(f"notes/{project_name}.json", "notes/backups/")
    notes_data = notes_manager.read_notes()  # Fetch notes data

    if notes_data is None:
        logging.error(f"Notes file {project_name} not found")
        return jsonify({'error': 'Notes file not found'}), 404

    if format_type == 'md':
        markdown_converter = MarkdownConverter()
        markdown_content = markdown_converter.convert_to_markdown(notes_data)  # Convert notes data to Markdown
        return markdown_content, 200, {'Content-Type': 'text/markdown'}

    return jsonify(notes_data), 200  # Default return format is JSON

@notes_blueprint.route('/<project_name>/add', methods=['POST'])
@api_auth_instance.require_api_key
def add_note(project_name):
    """
    Adds a new note to the specified notes file.

    Args:
        project_name (str): The project_name of the notes file to add the note to.

    Returns:
        JSON response indicating the success or failure of the operation.
    """
    notes_manager = NotesManager(f"notes/{project_name}.json", "notes/backups/")
    data = request.json
    note_content = data.get('content')
    level = data.get('level')
    identifier = data.get('identifier')
    note_id = notes_manager.add_note(note_content, level, identifier)
    
    logging.info(f"Note added to {project_name}: {note_id}")
    return jsonify({"message": "Note added successfully", "note_id": note_id}), 200

@notes_blueprint.route('/<project_name>/update', methods=['PUT'])
@api_auth_instance.require_api_key
def update_note(project_name):
    """
    Updates an existing note in the specified notes file.

    Args:
        project_name (str): The project_name of the notes file to update the note in.

    Returns:
        JSON response indicating the success or failure of the operation.
    """
    notes_manager = NotesManager(f"notes/{project_name}.json", "notes/backups/")
    data = request.json
    note_id = data.get('note_id')
    updated_content = data.get('content')
    level = data.get('level')
    identifier = data.get('identifier')
    
    success = notes_manager.update_note(note_id, updated_content, level, identifier)
    if success:
        logging.info(f"Note updated in {project_name}: {note_id}")
        return jsonify({"message": "Note updated successfully"}), 200
    else:
        logging.error(f"Failed to update note in {project_name}: {note_id}")
        return jsonify({"error": "Note not found or update failed"}), 404

@notes_blueprint.route('/<project_name>/delete', methods=['DELETE'])
@api_auth_instance.require_api_key
def delete_note(project_name):
    """
    Deletes a note from the specified notes file.

    Args:
        project_name (str): The project_name of the notes file to delete the note from.

    Returns:
        JSON response indicating the success or failure of the operation.
    """
    notes_manager = NotesManager(f"notes/{project_name}.json", "notes/backups/")
    data = request.json
    note_id = data.get('note_id')
    level = data.get('level')
    identifier = data.get('identifier')
    
    success = notes_manager.delete_note(note_id, level, identifier)
    if success:
        logging.info(f"Note deleted from {project_name}: {note_id}")
        return jsonify({"message": "Note deleted successfully"}), 200
    else:
        logging.error(f"Failed to delete note in {project_name}: {note_id}")
        return jsonify({"error": "Note not found or deletion failed"}), 404

```

## File: prompt_routes.py
```py
# ./prompt_routes.py
"""
Prompt Routes Module
--------------------
This module defines the Flask routes for retrieving markdown prompt documents. 
It handles requests for specific prompt documents from the 'prompts' directory, 
appending the '.md' extension in the backend. The module ensures secure access 
through API key authentication and maintains detailed logging for each operation.

Functions:
- get_prompt: Retrieves the content of a markdown file based on the project name.

Dependencies:
- prompt_retriever: Module for handling the retrieval of markdown files.
- require_api_key: Decorator from api_authenticator for API key validation.
"""

from flask import Blueprint, jsonify
from prompt_retriever import PromptRetriever
from api_authenticator import api_auth_instance
import logging

# Initialize Blueprint for prompt routes
prompt_blueprint = Blueprint('prompt_routes', __name__)
prompt_retriever = PromptRetriever("prompts")

@prompt_blueprint.route('/<project_name>', methods=['GET'])
#@api_auth_instance.require_api_key
def get_prompt(project_name):
    """
    Retrieves and returns the content of a markdown prompt file based on the project name.

    Args:
        project_name (str): The project name corresponding to the markdown file, without the .md extension.

    Returns:
        The content of the markdown file or an error message.
    """
    filename = f"{project_name}.md"
    content, error = prompt_retriever.get_prompt(filename)
    if error:
        logging.error(f"Error retrieving prompt for {filename}: {error}")
        return jsonify({'error': error}), 404
    return content, 200, {'Content-Type': 'text/plain; charset=utf-8'}

```

## File: notes_manager.py
```py
# ./notes_manager.py
"""
Notes Manager Module
--------------------
Manages notes stored in a JSON file within the notes directory. This module provides 
functionalities to read, write, add, update, and delete notes, handling data persistence 
and integrity. It includes error handling and logging to ensure robustness and reliability.

Classes:
- NotesManager: Manages operations related to notes stored in a JSON file.

Dependencies:
- json: For reading and writing JSON data.
- logging: For logging error and informational messages.
- os, datetime, shutil: For handling file operations and timestamp generation.
"""

import json
import logging
import os
from datetime import datetime
from shutil import copy2

class NotesManager:
    def __init__(self, notes_file_path, backup_dir):
        """
        Initializes the NotesManager with paths for notes file and backup directory.

        Args:
            notes_file_path (str): Path to the notes JSON file.
            backup_dir (str): Path to the directory where backups of notes file will be stored.
        """
        self.notes_file_path = notes_file_path
        self.backup_dir = backup_dir
        logging.basicConfig(level=logging.INFO)

    def backup_notes_file(self):
        """
        Creates a backup of the current notes file.
        """
        backup_file = os.path.join(self.backup_dir, f"backup_{datetime.now().strftime('%Y%m%d%H%M%S')}.json")
        try:
            copy2(self.notes_file_path, backup_file)
            logging.info(f"Backup created: {backup_file}")
        except Exception as e:
            logging.error(f"Failed to backup notes file: {e}")

    def read_notes(self):
        """
        Reads and returns the content of the notes file.

        Returns:
            dict: The content of the notes file.
        """
        try:
            with open(self.notes_file_path, 'r') as file:
                return json.load(file)
        except FileNotFoundError:
            logging.error("Notes file not found.")
            return {}
        except json.JSONDecodeError as e:
            logging.error(f"Error decoding JSON: {e}")
            return {}

    def write_notes(self, notes_data):
        """
        Writes the provided notes data to the notes file.

        Args:
            notes_data (dict): The notes data to write to the file.
        """
        self.backup_notes_file()
        try:
            with open(self.notes_file_path, 'w') as file:
                json.dump(notes_data, file, indent=4)
            logging.info("Notes file updated successfully.")
        except Exception as e:
            logging.error(f"Failed to write to notes file: {e}")

    def add_note(self, note_content, level, identifier=None):
        """
        Adds a new note to the specified level and identifier in the notes file.

        Args:
            note_content (str): The content of the note to be added.
            level (str): The level at which the note is to be added (e.g., project, file).
            identifier (str, optional): A specific identifier within the level (e.g., project_name).

        Returns:
            str: The ID of the added note.
        """
        notes_data = self.read_notes()
        note_id = str(max([int(k) for k in notes_data.get(level, {}).get('notes', {}).keys()], default=0) + 1)
        new_note = {
            "datetime": datetime.now().strftime("%Y-%m-%dT%H:%M:%S"),
            "content": note_content
        }

        if level not in notes_data:
            notes_data[level] = {"notes": {}}
        if identifier:
            if identifier not in notes_data[level]:
                notes_data[level][identifier] = {"notes": {}}
            notes_data[level][identifier]['notes'][note_id] = new_note
        else:
            notes_data[level]['notes'][note_id] = new_note

        self.write_notes(notes_data)
        logging.info(f"Note {note_id} added at level {level}, identifier {identifier}.")
        return note_id

    def update_note(self, note_id, updated_content, level, identifier=None):
        """
        Updates an existing note in the notes file.

        Args:
            note_id (str): The ID of the note to be updated.
            updated_content (str): The new content for the note.
            level (str): The level where the note resides.
            identifier (str, optional): A specific identifier within the level.

        Returns:
            bool: True if update was successful, False otherwise.
        """
        notes_data = self.read_notes()
        try:
            if identifier:
                notes_data[level][identifier]['notes'][note_id]['content'] = updated_content
            else:
                notes_data[level]['notes'][note_id]['content'] = updated_content
            self.write_notes(notes_data)
            logging.info(f"Note {note_id} at level {level}, identifier {identifier} updated.")
            return True
        except KeyError:
            logging.error(f"Note {note_id} to update not found at level {level}, identifier {identifier}.")
            return False

    def delete_note(self, note_id, level, identifier=None):
        """
        Deletes a note from the notes file.

        Args:
            note_id (str): The ID of the note to be deleted.
            level (str): The level where the note resides.
            identifier (str, optional): A specific identifier within the level.

        Returns:
            bool: True if deletion was successful, False otherwise.
        """
        notes_data = self.read_notes()
        try:
            if identifier:
                del notes_data[level][identifier]['notes'][note_id]
            else:
                del notes_data[level]['notes'][note_id]
            self.write_notes(notes_data)
            logging.info(f"Note {note_id} at level {level}, identifier {identifier} deleted.")
            return True
        except KeyError:
            logging.error(f"Note {note_id} to delete not found at level {level}, identifier {identifier}.")
            return False

```

## File: api_tester.py
```py
# api_tester.py
import requests
import json

# API Base URL
base_url = "https://api.ignite.webally.co.za"

# API Endpoints to test
endpoints = {
    "get_notes": f"{base_url}/notes/ignite?format=md",
    "add_note": f"{base_url}/notes/ignite/add",
    "update_note": f"{base_url}/notes/ignite/update",
    "delete_note": f"{base_url}/notes/ignite/delete",
    "get_prompt": f"{base_url}/prompts/ignite?format=md",
    "get_tasks": f"{base_url}/tasks/ignite?format=md",
    "get_specific_task": f"{base_url}/tasks/ignite/1?format=md",
    "get_specific_subtask": f"{base_url}/tasks/ignite/1/1?format=md"
}

# API Key
api_key = "_mu0WygMRETwooV39aj0PQ"

# Markdown Log File
log_file = "api_test_log.md"

def test_endpoint(name, url, method, data=None, params=None, overview="", expected_status=200):
    headers = {"X-API-Key": api_key, "Content-Type": "application/json"}
    response = None

    try:
        if method == "GET":
            response = requests.get(url, headers=headers, params=params)
        elif method == "POST":
            response = requests.post(url, json=data, headers=headers)
        elif method == "PUT":
            response = requests.put(url, json=data, headers=headers)
        elif method == "DELETE":
            response = requests.delete(url, json=data, headers=headers)

        if response and response.status_code == expected_status:
            log_response(name, url, response, overview)
        else:
            log_error(name, url, response, expected_status, overview)
    except Exception as e:
        log_exception(name, url, e, overview)

def log_response(name, url, response, overview):
    with open(log_file, "a") as file:
        file.write(f"# {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write("```json\n")
        file.write(json.dumps(response.json(), indent=2) if response else "No response")
        file.write("\n```\n\n")

def log_error(name, url, response, expected_status, overview):
    with open(log_file, "a") as file:
        file.write(f"# Error: {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(f"### Expected Status: {expected_status}\n")
        file.write(f"### Actual Status: {response.status_code if response else 'No Response'}\n")
        file.write("```json\n")
        file.write(json.dumps(response.json(), indent=2) if response else "No response")
        file.write("\n```\n\n")

def log_exception(name, url, exception, overview):
    with open(log_file, "a") as file:
        file.write(f"# Exception: {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(f"### Exception: {str(exception)}\n\n")

# Test each endpoint
test_endpoint("Get Notes", endpoints["get_notes"], "GET", overview="Testing retrieval of notes in Markdown format.")

# Test each endpoint
test_endpoint("Add Note", endpoints["add_note"], "POST", {"content": "Example note", "level": "project"}, overview="Testing addition of a new note.")

# Test each endpoint
test_endpoint("Update Note", endpoints["update_note"], "PUT", {"note_id": "1", "content": "Updated note content", "level": "project"}, overview="Testing update of an existing note.")

# Test each endpoint
test_endpoint("Delete Note", endpoints["delete_note"], "DELETE", {"note_id": "1", "level": "project"}, overview="Testing deletion of a note.")

# Test each endpoint
test_endpoint("Get Prompt", endpoints["get_prompt"], "GET", overview="Testing retrieval of a markdown prompt.")

# Test each endpoint
test_endpoint("Get Tasks", endpoints["get_tasks"], "GET", overview="Testing retrieval of tasks in Markdown format.")

# Test each endpoint
test_endpoint("Get Specific Task", endpoints["get_specific_task"], "GET", overview="Testing retrieval of a specific task in Markdown format.")

# Test each endpoint
test_endpoint("Get Specific Subtask", endpoints["get_specific_subtask"], "GET", overview="Testing retrieval of a specific subtask in Markdown format.")

# Testing retrieval of notes in Markdown format.
test_endpoint("Get Notes", endpoints["get_notes"], "GET", overview="Testing retrieval of notes in Markdown format.")

# Testing addition of a new note.
test_endpoint("Add Note", endpoints["add_note"], "POST", {"content": "Example note", "level": "project"}, overview="Testing addition of a new note.")

# Testing update of an existing note.
test_endpoint("Update Note", endpoints["update_note"], "PUT", {"note_id": "1", "content": "Updated note content", "level": "project"}, overview="Testing update of an existing note.")

# Testing deletion of a note.
test_endpoint("Delete Note", endpoints["delete_note"], "DELETE", {"note_id": "1", "level": "project"}, overview="Testing deletion of a note.")

# Testing retrieval of a markdown prompt.
test_endpoint("Get Prompt", endpoints["get_prompt"], "GET", overview="Testing retrieval of a markdown prompt.")

# Testing retrieval of tasks in Markdown format.
test_endpoint("Get Tasks", endpoints["get_tasks"], "GET", overview="Testing retrieval of tasks in Markdown format.")

# Testing retrieval of a specific task in Markdown format.
test_endpoint("Get Specific Task", endpoints["get_specific_task"], "GET", overview="Testing retrieval of a specific task in Markdown format.")

# Testing retrieval of a specific subtask in Markdown format.
test_endpoint("Get Specific Subtask", endpoints["get_specific_subtask"], "GET", overview="Testing retrieval of a specific subtask in Markdown format.")

# Testing retrieval of a task from a non-existent project - expected to fail.
test_endpoint("Invalid Task Retrieval", f"{base_url}/tasks/nonexistent_project", "GET", expected_status=404, overview="Expected to fail due to a non-existent project name.")

# Testing addition of a note to a non-existent project - expected to fail.
test_endpoint("Invalid Note Addition", f"{base_url}/notes/nonexistent_project/add", "POST", {"content": "Invalid note", "level": "project"}, expected_status=404, overview="Expected to fail as the project doesn't exist.")

# Testing update of a note with missing or invalid note ID - expected to fail.
test_endpoint("Invalid Note Update", f"{base_url}/notes/ignite/update", "PUT", {"content": "Updated note content", "level": "project"}, expected_status=400, overview="Fails due to missing or invalid note ID.")

# Testing deletion of a note with missing or invalid note ID - expected to fail.
test_endpoint("Invalid Note Deletion", f"{base_url}/notes/ignite/delete", "DELETE", expected_status=400, overview="Fails due to missing or invalid note ID.")

# Testing retrieval of a prompt from a non-existent project - expected to fail.
test_endpoint("Invalid Prompt Retrieval", f"{base_url}/prompts/nonexistent_project", "GET", expected_status=404, overview="Expected to fail due to a non-existent project name.")

# Testing retrieval of a task with a non-existent task number - expected to fail.
test_endpoint("Invalid Task Retrieval with Incorrect Task Number", f"{base_url}/tasks/ignite/nonexistent_task", "GET", expected_status=404, overview="Fails due to non-existent task number.")

# Testing retrieval of a subtask with a non-existent subtask number - expected to fail.
test_endpoint("Invalid Subtask Retrieval with Incorrect Subtask Number", f"{base_url}/tasks/ignite/1/nonexistent_subtask", "GET", expected_status=404, overview="Fails due to non-existent subtask number.")
```

## File: task_extractor.py
```py
# ./task_extractor.py
# This module is responsible for extracting specific tasks or subtasks from JSON data.

import logging

class TaskExtractor:
    def __init__(self):
        logging.basicConfig(level=logging.INFO)


    def extract_task_data(self, data, task_number):
        """
        Extracts and returns specific task or subtask data from JSON.
        Args:
        - data (dict): The JSON data.
        - task_number (str): The task number to extract, which can include subtasks like '1.1'.

        Returns:
        - dict: The extracted task or subtask data.
        """
        try:
            if '.' in task_number:
                sub_task = task_number
                main_task = task_number.split('.', 1)[0]
                print(f"sub_task: {sub_task}, main_task: {main_task}")
                task_data = data['tasks'][main_task][sub_task] 
                return {'tasks': {task_number: task_data}}
            else:
                return {'tasks': {task_number: data['tasks'][task_number]}}
        except KeyError as e:
            logging.error(f"Task or subtask not found: {task_number}. Error: {e}")
            return None
```

## File: prompt_retriever.py
```py
# ./prompt_retriever.py
"""
PromptRetriever Module
----------------------
This module provides functionality to retrieve and serve markdown files from the
'prompts' directory. It is designed to handle requests for specific prompt documents.

Classes:
- PromptRetriever: Handles the retrieval of markdown prompt files.
"""

import logging
import os

class PromptRetriever:
    def __init__(self, prompts_dir):
        self.prompts_dir = prompts_dir
        logging.basicConfig(level=logging.INFO)

    def get_prompt(self, filename):
        file_path = os.path.join(self.prompts_dir, filename)
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            return content, None  # No error
        except Exception as e:
            error = str(e)
            return None, error  # Content is None when there's an error
```

## File: app.py
```py
# ./app.py
"""
Main Flask application file that integrates the modular components for handling tasks, notes, and prompts.

This application provides APIs for task management, notes management, and prompt retrieval. It enforces API key authentication for secure access and integrates various functionalities in a modular fashion, ensuring maintainability and scalability.

Classes:
- Flask: The main class for the Flask application.
"""

from flask import Flask
import logging
from dotenv import load_dotenv
import os
from api_authenticator import api_auth_instance
from task_routes import task_blueprint
from notes_routes import notes_blueprint
from prompt_routes import prompt_blueprint

load_dotenv()
# Initialize Flask app and configure logging
app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# Register blueprints for tasks, notes, and prompts
app.register_blueprint(task_blueprint, url_prefix='/tasks')
app.register_blueprint(notes_blueprint, url_prefix='/notes')
app.register_blueprint(prompt_blueprint, url_prefix='/prompts')

if __name__ == '__main__':
    host_ip = os.getenv('HOST_IP', '127.0.0.1')
    port = os.getenv('PORT', 5000)  # You can add PORT to your .env if needed
    debug = os.getenv('FLASK_ENV') == 'development'  # debug is true if FLASK_ENV is 'development'

    app.run(host=host_ip, port=port, debug=debug)

```

## File: api_test_log.md
```md

```

## File: tasks/ignite_tasks.md
```md
# Project Overview
Automating code updates using AI with GPT-4 and OpenAI's Assistant API. This system includes a Chrome extension and a server component for efficient code modifications based on user inputs and screenshots.

## Key Steps

### 1. Install and Configure Code Server
- [x] 1.1. Choose a suitable server for installation.
- [X] 1.2. Install code-server following the official documentation.
- [X] 1.3. Configure access and security settings.
- [X] 1.4. Set up a domain or subdomain for code-server access.
- [X] 1.5. Test the code-server setup.

### 2. Develop Chrome Extension Basic Structure
- [ ] 2.1. Set up a new Chrome extension project.
- [ ] 2.2. Create a manifest file with necessary permissions.
- [ ] 2.3. Design a basic popup UI for the extension.
- [ ] 2.4. Implement background scripts for core functionalities.
- [ ] 2.5. Test the basic extension in Chrome.

### 3. Implement Screenshot Functionality
- [ ] 3.1. Research Chrome APIs for taking screenshots.
- [ ] 3.2. Write a function to capture the current tab.
- [ ] 3.3. Integrate screenshot functionality into the extension UI.
- [ ] 3.4. Test screenshot capture and storage.
- [ ] 3.5. Optimize screenshot quality and performance.

### 4. Create User Input Interface
- [ ] 4.1. Design a user-friendly input interface in the popup.
- [ ] 4.2. Implement form handling and data validation.
- [ ] 4.3. Ensure responsive design for different screen sizes.
- [ ] 4.4. Test the interface for usability.
- [ ] 4.5. Incorporate feedback mechanism for user inputs.

### 5. Set Up Server-Side Application
- [ ] 5.1. Choose a backend technology (Node.js, Python, etc.).
- [ ] 5.2. Initialize a new server application project.
- [ ] 5.3. Create API endpoints to receive data from the extension.
- [ ] 5.4. Implement data processing and storage mechanisms.
- [ ] 5.5. Test server functionality and extension communication.

### 6. Integrate OpenAI Assistant API
- [ ] 6.1. Obtain OpenAI API key and set up environment variables.
- [ ] 6.2. Write a function to send data to OpenAI API.
- [ ] 6.3. Process the API response for actionable insights.
- [ ] 6.4. Implement error handling and logging for the API integration.
- [ ] 6.5. Test API integration with sample data.

### 7. Handle Server Responses and Suggestions
- [ ] 7.1. Design logic to interpret suggestions from the API.
- [ ] 7.2. Map suggestions to actionable code updates.
- [ ] 7.3. Develop a system to apply updates to the codebase.
- [ ] 7.4. Test the application of updates in a controlled environment.
- [ ] 7.5. Set up rollback mechanisms in case of faulty updates.

### 8. Testing Extension-Server Communication
- [ ] 8.1. Create test cases for data transmission.
- [ ] 8.2. Simulate various user scenarios.
- [ ] 8.3. Monitor server logs during testing.
- [ ] 8.4. Optimize data transmission efficiency.
- [ ] 8.5. Ensure data integrity and security.

### 9. Link Extension with Code Server
- [ ] 9.1. Develop integration points between the extension and code-server.
- [ ] 9.2. Test extension access to the code-server environment.
- [ ] 9.3. Implement user authentication and authorization.
- [ ] 9.4. Ensure stable and secure connection.
- [ ] 9.5. Document the process for future users.

### 10. End-to-End System Test
- [ ] 10.1. Plan a comprehensive system test covering all components.
- [ ] 10.2. Document test cases and expected outcomes.
- [ ] 10.3. Execute the system test with a team.
- [ ] 10.4. Collect feedback and logs for analysis.
- [ ] 10.5. Make necessary adjustments based on test results.


```

## File: tests/api_tester.py
```py
import argparse
from test_config import endpoints
from test_runner import run_tests

# Setup argument parser
parser = argparse.ArgumentParser(description='API Tester for Ignite')
parser.add_argument('--test', type=int, help='The number of the test to run', default=None)

# Parse arguments
args = parser.parse_args()

# Run tests
run_tests(test_number=args.test)

```

## File: tests/test_config.py
```py
# test_config.py
# Configuration for API testing

# API Base URL
base_url = "https://api.ignite.webally.co.za"

# API Key
api_key = "_mu0WygMRETwooV39aj0PQ"  # Replace with your actual API key

# API Endpoints to test
endpoints = {
    "get_notes": f"{base_url}/notes/ignite?format=md",
    "add_note": f"{base_url}/notes/ignite/add",
    "update_note": f"{base_url}/notes/ignite/update",
    "delete_note": f"{base_url}/notes/ignite/delete",
    "get_prompt": f"{base_url}/prompts/ignite?format=md",
    "get_tasks": f"{base_url}/tasks/ignite?format=md",
    "get_specific_task": f"{base_url}/tasks/ignite/1?format=md",
    "get_specific_subtask": f"{base_url}/tasks/ignite/1/1?format=md"
}

```

## File: tests/test_runner.py
```py
# test_runner.py
# Executes the API tests
import requests
from test_cases import tests
from test_logger import log_response, log_error, log_exception, log_markdown_response, log_json_response
from test_config import api_key

def test_endpoint(name, url, method, data=None, params=None, overview="", expected_status=200):
    headers = {"X-API-Key": api_key, "Content-Type": "application/json"}
    response = None

    try:
        if method == "GET":
            response = requests.get(url, headers=headers, params=params)
        elif method == "POST":
            response = requests.post(url, json=data, headers=headers)
        elif method == "PUT":
            response = requests.put(url, json=data, headers=headers)
        elif method == "DELETE":
            response = requests.delete(url, json=data, headers=headers)

        # Check if response is successful and as expected
        if response and response.status_code == expected_status:
            # Check for Markdown or non-JSON response
            if response.headers.get('Content-Type') in ['text/markdown', 'text/plain']:
                log_markdown_response(name, url, response, overview)
            else:
                log_json_response(name, url, response, overview)
        else:
            log_error(name, url, response, expected_status, overview)
            log_response(name, url, response, overview)
    
    except Exception as e:
        log_exception(name, url, e, overview)

def run_tests(test_number=None):
    # Convert test_number to int if it's provided as a string
    if test_number is not None:
        try:
            test_number = int(test_number)
        except ValueError:
            print(f"Invalid test number: {test_number}")
            return

    if test_number is not None and 0 <= test_number < len(tests):
        test = tests[test_number]
        test_endpoint(test["name"], test["endpoint"], test["method"], 
                      data=test.get("data"), params=test.get("params"), 
                      overview=test["overview"], expected_status=test.get("expected_status", 200))
    else:
        for test in tests:
            test_endpoint(test["name"], test["endpoint"], test["method"], 
                          data=test.get("data"), params=test.get("params"), 
                          overview=test["overview"], expected_status=test.get("expected_status", 200))

if __name__ == "__main__":
    # Check for command line arguments
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        test_number = sys.argv[2] if len(sys.argv) > 2 else None
        run_tests(test_number)
    else:
        run_tests()
```

## File: tests/test_logger.py
```py
# test_logger.py
# Handles logging of test results

import json

log_file = "api_test_log.md"

def log_json_response(name, url, response, overview):
    with open(log_file, "w") as file:
        file.write(f"# {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(f"### Status Code: {response.status_code}\n")
        file.write("```json\n")
        file.write(json.dumps(response.json(), indent=4) if response else "No response")
        file.write("\n```\n\n")

def log_response(name, url, response, overview):
    with open(log_file, "w") as file:
        file.write(f"# {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write("```json\n")
        file.write(json.dumps(response.json(), indent=2) if response else "No response")
        file.write("\n```\n\n")

def log_error(name, url, response, expected_status, overview):
    with open(log_file, "w") as file:
        file.write(f"# Error: {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(f"### Expected Status: {expected_status}\n")
        file.write(f"### Actual Status: {response.status_code if response else 'No Response'}\n")
        file.write("```json\n")
        file.write(json.dumps(response.json(), indent=2) if response else "No response")
        file.write("\n```\n\n")

def log_exception(name, url, exception, overview):
    with open(log_file, "w") as file:
        file.write(f"# Exception: {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(f"### Exception: {str(exception)}\n\n")

def log_markdown_response(name, url, response, overview):
    # Log Markdown or plain text response
    with open(log_file, "w") as file:
        file.write(f"# {name}\n\n")
        file.write(f"## Overview\n{overview}\n\n")
        file.write(f"### Endpoint: {url}\n")
        file.write(response.text)  # Assuming response.text contains the Markdown content


```

## File: .env
```env
FLASK_ENV=production
FLASK_APP=app.py
HOST_IP=0.0.0.0
DB_HOST=127.0.0.1
DB_USER="cp"
DB_PASSWORD="4334.4334"
DB_PORT=3306
```

